setwd("~/Documents/My_papers/Semantic_discriptions/Protege/PhenoScript_R/PhenoScript/Dichotomius_paper/R_scripts")
setwd("~/Documents/My_papers/Semantic_discriptions/Protege/PhenoScript_R/PhenoScript/Dichotomius_paper/R_scripts/Functions")
source('parser_functions.R')
source_python('py_func.R')
#devtools::install_github('coolbutuseless/minilexer')
library(reticulate)
library("minilexer")
library("ontologyIndex")
#devtools::install_github("gadenbuie/regexplain")
#library("regexplain")
library("igraph")
library("stringr")
library("dplyr")
library("rdflib")
library(tidyr)
library(tibble)
library(jsonld)
library("redland")
source('parser_functions.R')
source_python('py_func.R')
# Setwd Descriptions
setwd("~/Documents/My_papers/Semantic_discriptions/Protege/PhenoScript_R/PhenoScript/Dichotomius_paper/Description")
descr <- readLines('D_annin.txt')
descr
# remove comments
descr <- str_remove(descr, '#.+')
# merge
descr <- paste0(descr, collapse = ' ')
# remove 2 or more whitespaces
descr <-str_squish(descr)
#str_view_all(descr, '\\s')
descr <-gsub('\n', '', descr)
descr <-strsplit(descr, '\\{')
descr <-descr[[1]][-1]
descr <-strsplit(descr, '\\}')
#
sp_names <- descr[[1]][1]
descr <-descr[[1]][2]
# remove unnecessary white speces (Ws, Ws)
descr <-str_replace_all(descr, '\\s\\)', '\\)')
descr <-str_replace_all(descr, '\\(\\s', '\\(')
# change not() to Not()
descr <-str_replace_all(descr, 'not\\(', 'Not\\(')
sp_descr <- lapply(descr, function(x) strsplit(x, ';')[[1]] )
# remove white at the beginning
sp_descr <-lapply(sp_descr, function(x) trimws(x))
names(sp_descr) <- sp_names[[1]]
sp_descr
# ADD HAS PART
sp_descr[[1]] <- sapply(sp_descr[[1]], function(x) add_HasPart_ophu(x), USE.NAMES = F )
sp_descr
man.syn <- sapply(sp_descr[[1]], function(x) create_ophus(x), USE.NAMES = F)
man.syn
#--- onto names for translations
# see Snippets.R, object 'all'
setwd("~/Documents/My_papers/Semantic_discriptions/Protege/PhenoScript_R/PhenoScript/Dichotomius_paper/R_scripts/data")
all <- read.csv(file='all_ontologies_tibble4Snippets.csv', stringsAsFactors = F)
all <-as_tibble(all)
all
# make lables for onto translations
all <-all %>% mutate(label.transl=label.final)
# add dot to properties and data_props
all <-all %>% mutate(label.transl=replace(label.transl, type=='prop', paste0(filter(all, type=='prop')$label.transl, '.') ))
all <-all %>% mutate(label.transl=replace(label.transl, type=='data_prop', paste0(filter(all, type=='data_prop')$label.transl, '.') ))
# add dot to IDs of properties and data_props
all <-all %>% mutate(ID.transl=ID)
all <-all %>% mutate(ID.transl=replace(ID.transl, type=='prop', paste0(filter(all, type=='prop')$ID.transl, '.') ))
all <-all %>% mutate(ID.transl=replace(ID.transl, type=='data_prop', paste0(filter(all, type=='data_prop')$ID.transl, '.') ))
filter(all, type=='prop')
filter(all, type=='prop') %>% select(label.transl, ID.transl)
all$label.transl
all$ID.transl
all$label.transl[all$label.transl=='SCARAB.has_measurement.']
# Remove SCARAB in labels
all$label.transl <- gsub('SCARAB.', '', all$label.transl)
all$ID.transl <- gsub('SCARAB.', 'scarab.', all$ID.transl)
all$label.transl[all$label.transl=='has_measurement.']
# make ttranslation obj
ont.transl <- all$label.transl
names(ont.transl) <-all$ID.transl
ont.transl
owl.syn <- sapply(man.syn, function(x) translate2URIs_oneToken(x, ont.transl, Manchester.pattern), USE.NAMES = F)
owl.syn
owl.syn
setwd("~/Documents/My_papers/Semantic_discriptions/Protege/PhenoScript_R/PhenoScript/Dichotomius_paper/Ontologies")
repl_python()
repl_python()
j <- 1
#for (j in 1:3){
for (i in 1:length(owl.syn)){
#  for (i in 1:5){
# CL1 <- py_make_class(class_id=paste0('ophu_sp_',j,'_', i), subclass_of='scarab.OPHU_EQ', restriction='is_a', def=owl.syn[i])
# py_run_string(CL1, local = FALSE, convert = F)
CL1 <- py_make_class(class_id=paste0('ophu_sp_',j,'_', i), subclass_of='scarab.OPHU_EQ', restriction='equivalent_to', def=owl.syn[i])
py_run_string(CL1, local = FALSE, convert = F)
# }
}
man.syn
py_run_string('scarab.save(file = "SCARAB_merged.owl", format = "rdfxml")', local = FALSE, convert = F)
owl.syn
man.syn.E <- sapply(sp_descr[[1]], function(x) create_ophus_E(x), USE.NAMES = F)
man.syn.E
owl.syn.E <- sapply(man.syn.E, function(x) translate2URIs_oneToken(x, ont.transl, Manchester.pattern), USE.NAMES = F)
owl.syn.E
for (i in 1:length(owl.syn.E)){
CL1 <- py_make_class(class_id=paste0('ophu_E_',i), subclass_of='OPHU_E', restriction='is_a', def=owl.syn.E[i])
py_run_string(CL1, local = FALSE, convert = F)
}
for (i in 1:length(owl.syn.E)){
CL1 <- py_make_class(class_id=paste0('ophu_E_',i), subclass_of='scarab.OPHU_E', restriction='is_a', def=owl.syn.E[i])
py_run_string(CL1, local = FALSE, convert = F)
}
py_run_string('scarab.save(file = "SCARAB_merged.owl", format = "rdfxml")', local = FALSE, convert = F)
ophu <- 'fore_wing has_part.(wing_vein bearer_of.(yellow))'
json.graph <- PhenSci2json(ophu, reserved.words.namespace='owl:', prop.namespace='obo:', id.prefix = '_test_',
brackets.new = c('{', '}') )
json.graph
cat(json.graph)
# Triplestore fromat
triple.ophu <- rdflib::rdf_parse(json.graph, "jsonld")
triple.ophu
# get type
trait_type(triple.ophu)
# plot
g <- triple2graph(triple.ophu)
plot(g)
# get Manchester fromat owlready
Manch <- graph2Manchester(g, qulifier='.some', prefix.remove='localhost:///', numeric.prefix='xsd:float',
escaped.words = c('not', 'min', 'max'))
Manch
# translate
translate2URIs_oneToken(Manch, ont.transl, Manchester.pattern)
# get triple Entity
g.E <- leave_triple_entity(triple.ophu)
g.E
plot(g.E)
# Manchester
Manch.E <- graph2Manchester(g.E, qulifier='.some', prefix.remove='localhost:///', numeric.prefix='xsd:float',
escaped.words = c('not', 'min', 'max'))
translate2URIs_oneToken(Manch.E, ont.transl, Manchester.pattern)
savehistory("~/Documents/My_papers/Semantic_discriptions/Protege/PhenoScript_R/PhenoScript/Dichotomius_paper/R_scripts/Seesion1'.Rhistory")
